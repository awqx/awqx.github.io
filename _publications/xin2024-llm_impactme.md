---
title: "LLMs detect depression outcomes"
collection: publications
category: manuscripts
permalink: /publication/2024-02-17-paper-title-number-4
excerpt: 'LLM-based classification models could identify outcomes important to adolescents, such as friendships or academic and vocational functioning, in text transcripts of patient interviews. By using clinical data, we also aim to better generalize to clinical settings compared to studies based on public social media data.'
date: 2024-12-11
venue: 'Journal of the American Medical Informatics Association'
paperurl: 'http://awqx.github.io/files/xin2024-llm_impactme.pdf'
citation: 'Xin AW, Nielson DM, Krause KR, Fiorini G, Midgley N, Pereira F, Lossio-Ventura JA. Using large language models to detect outcomes in qualitative studies of adolescent depression. Journal of the American Medical Informatics Association. 2024 Dec 11;ocae298.'
---

The full text is avilable on [the JAMIA website](https://doi.org/10.1093/jamia/ocae298).

## Abstract

### Objective

We aim to use large language models (LLMs) to detect mentions of nuanced psychotherapeutic outcomes and impacts than previously considered in transcripts of interviews with adolescent depression. Our clinical authors previously created a novel coding framework containing fine-grained therapy outcomes beyond the binary classification (eg, depression vs control) based on qualitative analysis embedded within a clinical study of depression. Moreover, we seek to demonstrate that embeddings from LLMs are informative enough to accurately label these experiences.

### Materials and Methods

Data were drawn from interviews, where text segments were annotated with different outcome labels. Five different open-source LLMs were evaluated to classify outcomes from the coding framework. Classification experiments were carried out in the original interview transcripts. Furthermore, we repeated those experiments for versions of the data produced by breaking those segments into conversation turns, or keeping non-interviewer utterances (monologues).

### Results

We used classification models to predict 31 outcomes and 8 derived labels, for 3 different text segmentations. Area under the ROC curve scores ranged between 0.6 and 0.9 for the original segmentation and 0.7 and 1.0 for the monologues and turns.
Discussion

LLM-based classification models could identify outcomes important to adolescents, such as friendships or academic and vocational functioning, in text transcripts of patient interviews. By using clinical data, we also aim to better generalize to clinical settings compared to studies based on public social media data.

### Conclusion

Our results demonstrate that fine-grained therapy outcome coding in psychotherapeutic text is feasible, and can be used to support the quantification of important outcomes for downstream uses.